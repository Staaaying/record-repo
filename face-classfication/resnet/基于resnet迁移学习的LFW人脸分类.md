# åŸºäºResNetè¿ç§»å­¦ä¹ çš„LFWäººè„¸è¯†åˆ«åˆ†ç±»

LFWæ•°æ®é›†(Labeled Faces in the Wild)æ˜¯é©¬è¨è¯¸å¡å¤§å­¦é˜¿å§†æ–¯ç‰¹åˆ†æ ¡è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€æ•´ç†åˆ¶ä½œçš„ä¸€ä¸ªéé™åˆ¶ç¯å¢ƒä¸‹äººè„¸æ•°æ®é›†ï¼ŒåŒ…å«5749äººåˆè®¡13233å¼ å›¾ç‰‡ï¼Œå›¾ç‰‡å¤§å°éƒ½æ˜¯250x250

æœ¬ä»£ç èƒŒæ™¯æ˜¯ä¸€ä»½CNNçš„äººè„¸åˆ†ç±»æŠ¥å‘Šï¼Œä»…éœ€è¦å®Œæˆç®€å•çš„äººè„¸åˆ†ç±»å³å¯ï¼Œä¸éœ€è¦å®Œæˆäººè„¸è¯†åˆ«ï¼Œå› æ­¤å°±å½“ä½œæ˜¯äººè„¸è¯†åˆ«çš„ç®€å•å…¥é—¨ï¼Œä¹‹åçš„è¯å¯èƒ½ä¼šæ ¹æ®è‡ªå·±çš„å…´è¶£åšä¸€ä¸ªäººè„¸è¯†åˆ«æ£€æµ‹çš„demoç¨‹åºç”¨åœ¨æ ‘è“æ´¾ä¸Šé¢

PS. åŸºäº**pytorch-gpu 1.5.1**å®ç°ï¼Œä½†æ˜¯ä¸ºäº†é€šç”¨æ€§æ‰€ä»¥æ”¹æˆäº†cpuç‰ˆæœ¬ï¼Œéœ€è¦ä½¿ç”¨gpuçš„åŒå­¦è¯·è‡ªè¡Œæ·»åŠ ç›¸åº”ä»£ç 

## æ•°æ®é›†å‡†å¤‡

### ä¸‹è½½æ•°æ®é›†

å¯ä»¥åˆ°[LFWå®˜ç½‘](http://vis-www.cs.umass.edu/lfw/)ä¸Šä¸‹è½½æ•°æ®é›†ï¼Œä¸‹è½½ä¹‹åä¼šæœ‰å¥½å‡ ä¸ªå‹ç¼©åŒ…ï¼Œæˆ‘ä»¬åªéœ€è¦å…¶ä¸­çš„**lfw.tgz**æ–‡ä»¶ï¼Œè§£å‹ä¹‹åå°±å¾—åˆ°äº†åŒ…å«æ‰€æœ‰å›¾ç‰‡çš„æ–‡ä»¶å¤¹

ä¹Ÿå¯ä»¥ç›´æ¥æ‹¿æˆ‘ä¸‹å¥½çš„æ•°æ®é›†ï¼Œä¸‹é¢æ˜¯åº¦å¨˜é“¾æ¥

é“¾æ¥ï¼šhttps://pan.baidu.com/s/152iVUmPoMDQN_B94hJWETA 
æå–ç ï¼š7a6h 
å¤åˆ¶è¿™æ®µå†…å®¹åæ‰“å¼€ç™¾åº¦ç½‘ç›˜æ‰‹æœºAppï¼Œæ“ä½œæ›´æ–¹ä¾¿å“¦--æ¥è‡ªç™¾åº¦ç½‘ç›˜è¶…çº§ä¼šå‘˜V5çš„åˆ†äº«(**ç‚«è€€ä¸‹æˆ‘çš„v5çš„(ï½ï¿£â–½ï¿£)ï½**)

### åˆ¶ä½œDataSet

è€ƒè™‘åˆ°LFWåŸå§‹æ•°æ®é›†ä¸­æœ‰å¾ˆå¤šäººåªæœ‰ä¸€å¼ ç…§ç‰‡ï¼Œä¹Ÿæœ‰éƒ¨åˆ†åäººï¼Œåƒå¸ƒä»€è¿™ç§ä¸€ä¸ªäººå°±æœ‰ä¸Šç™¾å¼ ç…§ç‰‡ï¼Œä¸€æ–¹é¢ä¸ºäº†ä¿æŒæ¯ä¸ªäººå¯¹åº”çš„äººè„¸ç…§ç‰‡é‡åˆé€‚ï¼Œå¦ä¸€æ–¹é¢å°½é‡å‡å°‘éœ€è¦åˆ†ç±»çš„äººçš„ä¸ªæ•°ä»¥å‡å°ç½‘ç»œå¤§å°æ–¹ä¾¿è®­ç»ƒï¼Œå› æ­¤éœ€è¦ä»LFWæ•°æ®é›†ä¸­æŒ‘é€‰ä¸€éƒ¨åˆ†ç…§ç‰‡ç”¨äºæœ¬æ¬¡å®éªŒã€‚è¿™é‡Œæœ€ç»ˆæŒ‘é€‰çš„æ˜¯æ‹¥æœ‰30-100å¼ ç…§ç‰‡çš„è¿™éƒ¨åˆ†äººï¼Œå…±æœ‰29äººï¼Œä¹Ÿå°±æ˜¯è¯´æœ€ç»ˆçš„CNNéœ€è¦åˆ†ç±»çš„ä¸ªæ•°ä¸º29ç±»ï¼Œå¯¹äºå°å®éªŒè€Œè¨€å¯ä»¥æ¥å—äº†

åˆ¶ä½œè¿‡ç¨‹åˆ†ä¸ºä»¥ä¸‹å‡ æ­¥ï¼š

1. è¯»å–æ–‡ä»¶å¤¹ï¼Œè·å–å›¾ç‰‡åŠäººå
2. æŒ‘é€‰å…¶ä¸­ç¬¦åˆè¦æ±‚çš„äººè„¸å›¾ç‰‡å¹¶å°†äººåè½¬æ¢ä¸ºæ•´æ•°æ ‡ç­¾
3. å¯¹äººè„¸å›¾ç‰‡è¿›è¡Œå˜æ¢åå’Œäººåæ ‡ç­¾ä¸€èµ·å­˜å…¥DataSet
4. å®šä¹‰DataLoaderç”¨äºåç»­è®­ç»ƒ

PS. åœ¨å›¾åƒå¤„ç†çš„æ—¶å€™ï¼Œå› ä¸ºResNetçš„å›¾ç‰‡è¾“å…¥å¤§å°æ˜¯224x224ï¼Œå› æ­¤åšäº†ä¸€ä¸ªä¸­å¿ƒè£å‰ª

```python
class MyDataSet(Dataset):
    '''
    å®šä¹‰æ•°æ®é›†ï¼Œç”¨äºå°†è¯»å–åˆ°çš„å›¾ç‰‡æ•°æ®è½¬æ¢å¹¶å¤„ç†æˆCNNç¥ç»ç½‘ç»œéœ€è¦çš„æ ¼å¼
    '''
    def __init__(self, DataArray, LabelArray):
        super(MyDataSet, self).__init__()
        self.data = DataArray
        self.label = LabelArray

    def __getitem__(self, index):
        # å¯¹å›¾ç‰‡çš„é¢„å¤„ç†æ­¥éª¤
        # 1. ä¸­å¿ƒç¼©æ”¾è‡³224(ResNetçš„è¾“å…¥å¤§å°)
        # 2. éšæœºæ—‹è½¬0-30Â°
        # 3. å¯¹å›¾ç‰‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œå‚æ•°æ¥æºä¸ºpytorchå®˜æ–¹æ–‡æ¡£
        im_trans = transforms.Compose([
            transforms.ToPILImage(),
            transforms.CenterCrop(size=224),
            transforms.RandomRotation((0, 30)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                [0.229, 0.224, 0.225])
        ])
        return im_trans(self.data[index]), t.tensor(self.label[index], dtype=t.long)

    def __len__(self):
        return self.label.shape[0]

# è¯»å–LFWæ•°æ®é›†ï¼Œå°†å›¾ç‰‡æ•°æ®è¯»å…¥æ•°ç»„å¹¶å°†åå­—è½¬æ¢ä¸ºæ ‡ç­¾
path = r'face+\lfw'
pathlist = map(lambda x: '\\'.join([path, x]), os.listdir(path))
namedict = {}
data, label = [], []
idx = 0
for item in pathlist:
    dirlist = os.listdir(item)
    # é€‰å–æ‹¥æœ‰30-100å¼ ç…§ç‰‡çš„äººä½œä¸ºæ•°æ®æ¥æº
    # å¤ªå°‘ç½‘ç»œä¸å®¹æ˜“å­¦ä¹ åˆ°å…¶äººè„¸ç‰¹å¾ï¼Œå¤ªå¤šçš„è¯åˆ™å®¹æ˜“è¿‡æ‹Ÿåˆ
    if not (30<= len(dirlist) <= 100):
        continue
    # data:     å­˜å‚¨äººåƒç…§ç‰‡çš„ä¸‰é€šé“æ•°æ®
    # label:    å­˜å‚¨äººåƒçš„å¯¹åº”æ ‡ç­¾(æ•´æ•°)
    # namedict: è®°å½•labelä¸­æ•´æ•°ä¸äººåçš„å¯¹åº”å…³ç³»
    for picpath in dirlist:
        data.append(image.imread(item + '\\' + picpath))
        label.append(idx)
    namedict[str(idx)] = item.split('\\')[-1]
    idx += 1

# éšæœºæ‰“ä¹±æ•°æ®ï¼Œé‡æ–°æ’åºå¹¶æŒ‰ç…§8:2çš„æ¯”ä¾‹åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
data, label = np.stack(data), np.array(label)
idx = np.random.permutation(data.shape[0])
data, label = data[idx], label[idx]
train_X, test_X, train_Y, test_Y = train_test_split(data, label, test_size=0.2)

# å°†åˆ†å‰²å¥½çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†å¤„ç†ä¸ºpytorchæ‰€éœ€çš„æ ¼å¼
TrainSet = MyDataSet(train_X, train_Y)
TestSet = MyDataSet(test_X, test_Y)
TrainLoader = DataLoader(TrainSet, batch_size=32, shuffle=True, drop_last=True)
TestLoader = DataLoader(TestSet, batch_size=32, shuffle=True, drop_last=True)
```

## è°ƒç”¨ResNet18

pytorchå®˜æ–¹æä¾›äº†å¾ˆå¤šCNNç½‘ç»œçš„ç°æˆç‰ˆæœ¬å¯ä»¥ç›´æ¥è°ƒç”¨ï¼Œå°±ä¸ç”¨è‡ªå·±è´¹åŠ›å»å†™äº†ã€‚è€Œä¸”å®˜æ–¹æä¾›çš„ç½‘ç»œéƒ½æœ‰é¢„è®­ç»ƒç‰ˆæœ¬ï¼Œå¯ä»¥ç›´æ¥æ‹¿åœ¨ImageNetè®­ç»ƒè¿‡çš„CNNç½‘ç»œåœ¨æˆ‘ä»¬çš„ç®€æ˜“LFWæ•°æ®é›†ä¸Šç¨å¾®è®­ç»ƒå¾®è°ƒï¼Œä»è€Œå®ç°è¿ç§»å­¦ä¹ ï¼Œæ•ˆæœä¸€èˆ¬éƒ½ä¼šæ¯”è¾ƒå¥½ã€‚

è€ƒè™‘åˆ°æˆ‘ä»¬ç®€æ˜“LFWæ•°æ®é›†çš„è§„æ¨¡ï¼Œç”¨**ResNet18**å°±å¯ä»¥äº†ï¼ŒæŠŠ**pretrained**å±æ€§è®¾ç½®ä¸º**True**ä½¿ç”¨é¢„è®­ç»ƒç‰ˆæœ¬ï¼Œåˆå§‹ä½¿ç”¨çš„è¯ä¼šè‡ªåŠ¨ä¸‹è½½ç½‘ç»œå‚æ•°ï¼Œéœ€è¦ç­‰ä¸€ä¼šã€‚ResNet18æ¨¡å‹æ²¡åŠæ³•ç›´æ¥è¿ç”¨åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸Šï¼Œéœ€è¦åšå¦‚ä¸‹ä¸‰ç‚¹å˜æ¢

1. å°†è¾“å…¥å›¾ç‰‡çš„å¤§å°è½¬ä¸ºN x C x 224 x 244
2. å°†**ResNet18**ç½‘ç»œä¸­çš„**requires_grad**ç½®ä¸ºFalseï¼Œä½¿å…¶åç»­ä¸å‚ä¸è®­ç»ƒæ›´æ–°(å¯è®¾ç½®ä¹Ÿå¯ä»¥ä¸è®¾ç½®ï¼Œçœ‹å“ªä¸ªæ•ˆæœå¥½è€Œå®šï¼Œä¸è¿‡ä¸æ›´æ–°ResNetç½‘ç»œå‚æ•°çš„è¯è®­ç»ƒæ›´æ–°ä¼šæ›´å¿«ï¼Œä½†æ˜¯é€šå¸¸æ•ˆæœä¼šå·®ä¸€äº›)
3. å°†**ResNet18**ç½‘ç»œçš„**fc**åˆ†ç±»å¤´æ”¹ä¸ºé€‚åˆæˆ‘ä»¬æ•°æ®é›†çš„å¤§å°

```python
# è°ƒç”¨é¢„è®­ç»ƒçš„resnet18è¿›è¡Œè¿ç§»å­¦ä¹ 
# resnet50å‚æ•°é‡è¿‡å¤šï¼Œè®­ç»ƒæ•ˆæœä¸å¤ªå¥½
resnet = models.resnet18(pretrained=True)
for param in resnet.parameters():
    param.requires_grad = False

# å°†resnetçš„è¾“å‡ºfc(å…¨è¿æ¥å±‚)æ›¿æ¢ä¸ºæœ¬ä»»åŠ¡æ‰€éœ€çš„æ ¼å¼
# 1000-->256-->relu-->dropout-->29-->softmax
fc_inputs = resnet.fc.in_features
resnet.fc = nn.Sequential(
    nn.Linear(fc_inputs, 256),
    nn.ReLU(),
    nn.Dropout(),
    nn.Linear(256, 29)
)
```

## è¿›è¡Œè¿ç§»å­¦ä¹ 

ä¹‹åçš„æ­¥éª¤å°±è·Ÿé€šå¸¸çš„CNNè®­ç»ƒæ²¡æœ‰åŒºåˆ«äº†ï¼Œè®¾ç½®å¥½å‚æ•°æŒ‰ç…§æ¨¡æ¿è¿›è¡Œè®­ç»ƒå³å¯ï¼Œç”±äºè¿ç§»å­¦ä¹ çš„æ•ˆæœæ¯”è¾ƒå¥½ï¼Œå› æ­¤è¿™é‡Œä¹Ÿä¸éœ€è¦ç‰¹åˆ«è®¾ç½®ç½‘ç»œè®­ç»ƒçš„å‚æ•°ï¼Œä¿æŒé»˜è®¤å³å¯

```python
# å®šä¹‰äº¤å‰ç†µæŸå¤±å‡½æ•°å’ŒAdamä¼˜åŒ–å™¨(å­¦ä¹ ç‡ï¼Œæƒé‡è¡°å‡ä½¿ç”¨é»˜è®¤å€¼)
loss = nn.CrossEntropyLoss()
optimizer = t.optim.Adam(resnet.parameters())

def train(net, dataloader, testdataloader, optimizer, criterion, epocs=20):
    # ä»¥ä¸‹å››ä¸ªå‚æ•°åˆ†åˆ«ç”¨äºå­˜å‚¨è®­ç»ƒå’Œæµ‹è¯•çš„æŸå¤±å‡½æ•°å€¼ä»¥åŠåˆ†ç±»å‡†ç¡®ç‡
    train_loss_arr, train_acc_arr, test_loss_arr, test_acc_arr = [], [], [], []
    for epoc in range(epocs):
        net.train()
        TrainLoss, TrainAcc = 0, 0
        for BatchIdx, (InputData, Labels) in enumerate(dataloader):
            Outputs = net(InputData)
            optimizer.zero_grad()
            loss = criterion(Outputs.squeeze(), Labels)
            loss.backward()
            optimizer.step()
            TrainLoss += loss.item()
            _, pred = t.max(Outputs.data, 1)
            TrainAcc += t.mean(pred.eq(Labels.data.view_as(pred)).type(t.FloatTensor)).item() * len(InputData)
            if BatchIdx % 10 == 0 and BatchIdx > 0:
                print('Bathch: {}/{}\tLoss: {}\tAcc: {}%'.format(BatchIdx, len(dataloader), round(TrainLoss, 2), 
                                                                 round(100*TrainAcc/((BatchIdx+1) * InputData.shape[0]), 2)))
        train_acc_arr.append(100*TrainAcc/(len(dataloader)*32))
        train_loss_arr.append(TrainLoss)
        TestLoss, TestAcc = 0, 0
        with t.no_grad():
            net.eval()
            for BatchIdx, (InputData, Labels) in enumerate(testdataloader):
                Outputs = net(InputData)
                loss = criterion(Outputs.squeeze(), Labels)
                TestLoss += loss.item()
                _, pred = t.max(Outputs.data, 1)
                TestAcc += t.mean(pred.eq(Labels.data.view_as(pred)).type(t.FloatTensor)).item() * len(InputData)
            print('Loss: {}\tAcc: {}%'.format(round(TrainLoss, 2),
                                              round(100*TestAcc/(len(testdataloader) * 32), 2)))
            print('-'*60)  
        test_acc_arr.append(100*TestAcc/(len(testdataloader)*32))
        test_loss_arr.append(TestLoss)
    return train_loss_arr, train_acc_arr, test_loss_arr, test_acc_arr

# è¿›è¡Œè®­ç»ƒå¹¶ç»˜åˆ¶è®­ç»ƒæ›²çº¿
train_loss_arr, train_acc_arr, test_loss_arr, test_acc_arr = train(resnet, TrainLoader, TestLoader, optimizer, loss)
fig = plt.figure()
ax1 = fig.add_subplot(121)
ax1.plot(train_loss_arr, label='train loss')
ax1.plot(test_loss_arr, label='test loss')
ax1.legend()
ax1.set_title('Loss Curve')
ax1.set_xlabel('epocs')
ax1.set_ylabel('loss')
ax2 = fig.add_subplot(122)
ax2.plot(train_acc_arr, label='train acc')
ax2.plot(test_acc_arr, label='test acc')
ax2.legend()
ax2.set_title('Accuracy Curve')
ax2.set_xlabel('epocs')
ax2.set_ylabel('loss')
plt.show()

# æ‰“å°æµ‹è¯•é›†çš„çœŸå®/é¢„æµ‹ç»“æœ
for InputData, Labels in enumerate(TestSet):
    Outputs = resnet(Labels[0].unsqueeze(0))
    _, pred = t.max(Outputs.data, 1)
    pred_name = namedict[str(pred.item())]
    real_name = namedict[str(Labels[1].item())]
    print('real name: {}\t\t\t\tpredict name: {}'.format(real_name, pred_name))
t.save(resnet, r'face+\resnet.pth')
```

## æ¨¡å‹åˆ†ç±»ç»“æœ

è®­ç»ƒå®Œæˆåæ¨¡å‹çš„åˆ†ç±»å‡†ç¡®ç‡è®­ç»ƒé›†ä¸Šå·®ä¸å¤š99%ï¼Œæµ‹è¯•é›†ä¸Šæœ€é«˜å¯ä»¥åˆ°90%ï¼Œè¿˜æ˜¯æ¯”è¾ƒç¬¦åˆé¢„æœŸäº†ï¼Œæ¯•ç«Ÿæ•´ä¸ªç½‘ç»œå…¶å®æ²¡æœ‰è¿›è¡Œå¤ªå¤šçš„è°ƒæ•´

![2e0f7c211c9bf84603ad2fcdf3008f3](http://typora-staaaying.oss-cn-chengdu.aliyuncs.com/img/2e0f7c211c9bf84603ad2fcdf3008f3.png)

æ‹¿**lfw_test**ä¸­çš„8å¼ äººè„¸ç…§ç‰‡è¿›è¡Œæµ‹è¯•ï¼Œå…¶ä¸­6å¼ æ­£ç¡®ï¼Œ2å¼ é”™è¯¯ï¼Œçœ‹äº†ä¸‹åˆ†ç±»é”™è¯¯çš„ä¸¤å¼ ä¹‹ä¸€

![Jean_Chretien_0055](http://typora-staaaying.oss-cn-chengdu.aliyuncs.com/img/Jean_Chretien_0055.jpg)![David_Beckham_0024](http://typora-staaaying.oss-cn-chengdu.aliyuncs.com/img/David_Beckham_0024.jpg)

å·¦è¾¹æ˜¯**Jean Chretien(åŠ æ‹¿å¤§å‰æ€»ç†)**ï¼Œå³è¾¹æ˜¯**å¤§åé¼é¼çš„è´å…‹æ±‰å§†**ï¼Œç½‘ç»œæŠŠæ€»ç†çš„äººè„¸ç…§ç‰‡é”™è¯¯è¯†åˆ«æˆäº†è´å…‹æ±‰å§†ã€‚è®²é“ç†ï¼Œæœ‰ä¸€è¯´ä¸€ï¼Œæˆ‘è§‰å¾—æ²¡å•¥æ¯›ç—…ï¼Œæ€»ç†ä¹ŸæŒºå¸…çš„ğŸ˜ğŸ˜ğŸ˜

æœ‰å…´è¶£çš„åŒå­¦ä¹Ÿå¯ä»¥äº†è§£ä¸‹æ€»ç†çš„æ•…äº‹ï¼Œè¿˜æŒºåŠ±å¿—çš„ã€‚

å®Œæ•´ä»£ç GitHubåœ°å€ï¼šhttps://github.com/Staaaying/record-repo/face-classfication/resnet